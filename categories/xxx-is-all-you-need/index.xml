<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>XXX is All You Need | Abing's Blog</title><link>https://blog.abingcbc.cn/categories/xxx-is-all-you-need/</link><atom:link href="https://blog.abingcbc.cn/categories/xxx-is-all-you-need/index.xml" rel="self" type="application/rss+xml"/><description>XXX is All You Need</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>zh-cn</language><lastBuildDate>Sun, 30 Oct 2022 21:00:00 +0000</lastBuildDate><item><title>Sealos is All You Need —— 3分钟部署 Kubernetes</title><link>https://blog.abingcbc.cn/posts/sealos/</link><pubDate>Sun, 30 Oct 2022 21:00:00 +0000</pubDate><guid>https://blog.abingcbc.cn/posts/sealos/</guid><description>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./f6ce5cbedc6aa338007cd4633935ad371086271c.png" alt="title.png" />
&lt;/figure>
&lt;/p>
&lt;h2 id="sealos-是什么" class="relative group">Sealos 是什么？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#sealos-%e6%98%af%e4%bb%80%e4%b9%88" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>Kubernetes（K8s）发展至今，已经成为了一个极其复杂的系统。而作为云原生的基石，涌现了一大批辅助工具，帮助用户快速搭建 k8s 集群。而其中，&lt;a
href="https://github.com/labring/sealos"
target="_blank" rel="noreferrer noopener"
>sealos&lt;/a> 是一个以 kubernetes 为内核的云操作系统，kuberentes 生命周期管理是 sealos 的一个重要功能，sealos 可以非常方便的安装/升级/伸缩/备份恢复集群等。接下来，让我们通过一个例子来看看 sealos 的强大。&lt;/p>
&lt;h2 id="如何使用" class="relative group">如何使用 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./313c52bda7b27b5b64a479e488404bcef56b2669.png" alt="Frame 3.png" />
&lt;/figure>
&lt;/p>
&lt;p>假设我们想要在 192.168.0.100，192.168.0.101 和 192.168.0.102 这三台机器上部署一主两从的 K8s 集群，那么使用 Sealos 的话，主要输入以下的命令：&lt;/p>
&lt;pre tabindex="0">&lt;code>sudo sealos run labring/kubernetes:v1.24.0 labring/calico:v3.22.1 \
--masters 192.168.0.100 \
--nodes 192.168.0.101,192.168.0.102 \
    --passwd xxx
&lt;/code>&lt;/pre>&lt;p>是的，Sealos 将一个复杂的 K8s 的集群部署简化成了短短一行命令，将部署体验拉到了极致。甚至不需要过多的文档解释，仅凭这一行命令就可以满足大多数普通的部署场景。&lt;/p>
&lt;h2 id="原理" class="relative group">原理 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%8e%9f%e7%90%86" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>那么，如此强大的 Sealos 是如何运行的呢？除了刚才演示的 &lt;code>run&lt;/code> 命令之外，Sealos 还提供了大量提升用户体验的命令，例如 &lt;code>create&lt;/code> 创建镜像、&lt;code>reset&lt;/code> 格式化集群等等。由于篇幅有限，本章节就以最核心的 &lt;code>run&lt;/code> 命令为例，看看 Sealos 在背后替用户完成了哪些自动化的操作。（本文以 Sealos V4.1.0 代码为例）&lt;/p>
&lt;h3 id="applier" class="relative group">Applier &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#applier" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>首先，Sealos 会创建一个 &lt;code>Applier&lt;/code> 结构体，负责了部署集群的核心逻辑。&lt;code>Applier&lt;/code> 采用了 k8s 的声明式的设计思想，用户声明一个期望的集群状态，而 &lt;code>Applier&lt;/code> 负责将集群现在的状态转换成用户期望的状态。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">type&lt;/span> &lt;span class="nx">Applier&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">ClusterDesired&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">v2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Cluster&lt;/span> &lt;span class="c1">// 用户期望的集群状态
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">ClusterCurrent&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">v2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Cluster&lt;/span> &lt;span class="c1">// 集群当前状态
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">ClusterFile&lt;/span> &lt;span class="nx">clusterfile&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Interface&lt;/span> &lt;span class="c1">// 当前集群接口
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">Client&lt;/span> &lt;span class="nx">kubernetes&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Client&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">CurrentClusterInfo&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">version&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Info&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">RunNewImages&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">string&lt;/span> &lt;span class="c1">// run 命令新增的镜像名称
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>clusterfile.Interface&lt;/code> 是一个接口类型，Sealos 中通过 &lt;code>ClusterFile&lt;/code> 实现了这一接口。因此，&lt;code>Applier&lt;/code> 结构体中最重要的就是 &lt;code>Cluster&lt;/code> 和 &lt;code>ClusterFile&lt;/code> 这两个类型，它们定义了集群的状态和配置。接下来，我们展开介绍一下两者。&lt;/p>
&lt;h4 id="cluster" class="relative group">Cluster &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#cluster" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">type&lt;/span> &lt;span class="nx">Cluster&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">metav1&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">TypeMeta&lt;/span> &lt;span class="s">`json:&amp;#34;,inline&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">metav1&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">ObjectMeta&lt;/span> &lt;span class="s">`json:&amp;#34;metadata,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Spec&lt;/span> &lt;span class="nx">ClusterSpec&lt;/span> &lt;span class="s">`json:&amp;#34;spec,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Status&lt;/span> &lt;span class="nx">ClusterStatus&lt;/span> &lt;span class="s">`json:&amp;#34;status,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">type&lt;/span> &lt;span class="nx">ClusterSpec&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Image&lt;/span> &lt;span class="nx">ImageList&lt;/span> &lt;span class="s">`json:&amp;#34;image,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">SSH&lt;/span> &lt;span class="nx">SSH&lt;/span> &lt;span class="s">`json:&amp;#34;ssh&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Hosts&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="nx">Host&lt;/span> &lt;span class="s">`json:&amp;#34;hosts,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Env&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">string&lt;/span> &lt;span class="s">`json:&amp;#34;env,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Command&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">string&lt;/span> &lt;span class="s">`json:&amp;#34;command,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kd">type&lt;/span> &lt;span class="nx">ClusterStatus&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Phase&lt;/span> &lt;span class="nx">ClusterPhase&lt;/span> &lt;span class="s">`json:&amp;#34;phase,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Mounts&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="nx">MountImage&lt;/span> &lt;span class="s">`json:&amp;#34;mounts,omitempty&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Conditions&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="nx">ClusterCondition&lt;/span> &lt;span class="s">`json:&amp;#34;conditions,omitempty&amp;#34; `&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>Cluster&lt;/code> 的内容按照 K8s Resource 的格式进行了设计，这非常的 K8s 哈哈。在 &lt;code>ClusterSpec&lt;/code> 中，定义了一系列用于部署 K8s 集群的参数，例如，镜像、SSH参数、节点等等。&lt;/p>
&lt;p>而在 &lt;code>ClusterStatus&lt;/code> 中，&lt;code>Phase&lt;/code> 定义了当前集群的状态，&lt;code>Mounts&lt;/code> 定义了集群使用的镜像，&lt;code>Conditions&lt;/code> 保存了集群中所发生的一系列事件。&lt;/p>
&lt;h4 id="clusterfile" class="relative group">ClusterFile &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#clusterfile" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">type&lt;/span> &lt;span class="nx">ClusterFile&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">path&lt;/span> &lt;span class="kt">string&lt;/span> &lt;span class="c1">// 保存路径
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">customValues&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">string&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">customSets&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">string&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">customEnvs&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="kt">string&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">Cluster&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">v2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Cluster&lt;/span> &lt;span class="c1">// 集群状态
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">Configs&lt;/span> &lt;span class="p">[]&lt;/span>&lt;span class="nx">v2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Config&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">KubeConfig&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="nx">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">KubeadmConfig&lt;/span> &lt;span class="c1">// 集群配置
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>ClusterFile&lt;/code> 是真正被 &lt;code>Applier&lt;/code> 操作的对象，以及持久化到文件中的内容。这里包含了所有集群的当前状态信息，同时还包含了 kubeconfig。这里的 kubeconfig 并不是我们平时操作 k8s 时所用的 config 文件，而是一系列用于搭建集群所需的配置项。在使用 &lt;code>kubeadm&lt;/code> 时，这些配置项往往需要我们手动配置，而 Sealos 在这里会自动帮我们填写并应用于集群中。可以看出，&lt;code>Cluster&lt;/code> 更像是 &lt;code>ClusterFile&lt;/code> 的一个实例，记录了集群实时的状态。&lt;/p>
&lt;h3 id="创建-applier" class="relative group">创建 Applier &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%88%9b%e5%bb%ba-applier" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>创建一个 &lt;code>Applier&lt;/code> 会经过以下步骤：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>判断是否已经存在 &lt;code>ClusterFile&lt;/code> ，如果存在，那么直接读取，构建出集群状态 &lt;code>Cluster&lt;/code>。否则，初始化创建一个空的集群状态 &lt;code>Cluster&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>根据用户本次的参数，更新集群状态 &lt;code>Cluster&lt;/code> 中的 spec，此时，&lt;code>Cluster&lt;/code> 即为目标的集群状态。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>再次从文件中构建 &lt;code>ClusterFile&lt;/code>，作为集群当前的状态和对象。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>构建 &lt;code>Applier&lt;/code> 结构体返回。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="apply" class="relative group">Apply &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#apply" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>接下来，通过 &lt;code>Applier.Apply()&lt;/code>，Sealos 开始正式的部署集群，使集群状态向目标靠近。首先，Sealos 会将当前集群的状态置为 &lt;code>ClusterInProcess&lt;/code>。接下来，根据集群创建或是更新，分别进入两个分支。&lt;/p>
&lt;h4 id="initcluster" class="relative group">initCluster &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#initcluster" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>&lt;code>initCluster&lt;/code> 负责从零开始创建一个集群。函数中会通过 &lt;code>CreateProcessor&lt;/code> 去部署期望状态的集群。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">type&lt;/span> &lt;span class="nx">CreateProcessor&lt;/span> &lt;span class="kd">struct&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">ClusterFile&lt;/span> &lt;span class="nx">clusterfile&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Interface&lt;/span> &lt;span class="c1">// 当前集群对象
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">ImageManager&lt;/span> &lt;span class="nx">types&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">ImageService&lt;/span> &lt;span class="c1">// 处理镜像
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">ClusterManager&lt;/span> &lt;span class="nx">types&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">ClusterService&lt;/span> &lt;span class="c1">// 管理 clusterfile
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">RegistryManager&lt;/span> &lt;span class="nx">types&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">RegistryService&lt;/span> &lt;span class="c1">// 管理镜像 registry
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">Runtime&lt;/span> &lt;span class="nx">runtime&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Interface&lt;/span> &lt;span class="c1">// kubeadm 对象
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span> &lt;span class="nx">Guest&lt;/span> &lt;span class="nx">guest&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Interface&lt;/span> &lt;span class="c1">// 基于 sealos 的应用对象
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./c668a66b40dbc788695a9cbb8ec3f76a9897503a.png" alt="Slide 16_9 - 1.png" />
&lt;/figure>
&lt;/p>
&lt;p>&lt;code>CreateProcessor.Execute&lt;/code> 接收期望的集群状态 &lt;code>ClusterDesired&lt;/code>。接下来会执行一系列 pipeline，正式进入实际的集群部署过程中：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Check：检查集群的 host&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PreProcess：负责集群部署前的镜像预处理操作，在这里就会利用 &lt;code>CreateProcessor&lt;/code> 中的各个 Manager。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>拉取镜像&lt;/p>
&lt;/li>
&lt;li>
&lt;p>检查镜像格式&lt;/p>
&lt;/li>
&lt;li>
&lt;p>使用 &lt;code>buildah&lt;/code> 从 OCI 格式的镜像中创建 working container，并将容器挂载到 rootfs 上&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将容器的 manifest 添加到集群状态中&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>RunConfig：将集群状态中的 working container 导出成 yaml 格式的配置并持久化到宿主机的文件系统中&lt;/p>
&lt;/li>
&lt;li>
&lt;p>MountRootfs：将挂载的镜像内容按照类别，以 &lt;code>rootfs&lt;/code>，&lt;code>addons&lt;/code>，&lt;code>app&lt;/code> 的顺序分发到每台机器上。&lt;/p>
&lt;p>这里需要介绍一下 sealos 镜像的一般结构，以最基础的 k8s 镜像为例：&lt;/p>
&lt;pre tabindex="0">&lt;code>labring/kubernetes
- etc // 配置项
- scripts // 脚本
    - init-containerd.sh
    - init-kube.sh
    - init-shim.sh
    - init-registry.sh
    - init.sh
- Kubefile // dockerfile 语法，定义了镜像的执行逻辑
&lt;/code>&lt;/pre>&lt;p>K8s 作为整个集群的基础，虽然最终镜像内的目录结构与其他一致，但其构建过程稍微有所不同。在 CI &lt;a
href="https://github.com/labring/cluster-image/blob/faca63809e7a3eae512100a1eb8f9b7384973175/.github/scripts/kubernetes.sh#L35"
target="_blank" rel="noreferrer noopener"
>https://github.com/labring/cluster-image/blob/faca63809e7a3eae512100a1eb8f9b7384973175/.github/scripts/kubernetes.sh#L35&lt;/a> 中，我们可以看到，k8s 镜像其实是合并了 cluster-image 仓库下的多个文件夹，&lt;code>containerd&lt;/code>，&lt;code>rootfs&lt;/code> 和 &lt;code>registry&lt;/code>。这些独立的文件夹中包含有安装对应组件的脚本。&lt;/p>
&lt;p>Sealos 在挂载一个镜像后，会首先执行 &lt;code>init.sh&lt;/code> 脚本。例如，以下是 k8s 镜像的脚本中，分别按顺序执行了 &lt;code>init-containerd.sh&lt;/code> 安装 containerd，&lt;code>init-shim.sh&lt;/code> 安装 image-cri-shim 和 &lt;code>init-kube.sh&lt;/code> 安装 kubelet。&lt;/p>
&lt;pre tabindex="0">&lt;code>source common.sh
REGISTRY_DOMAIN=${1:-sealos.hub}
REGISTRY_PORT=${2:-5000}
# Install containerd
chmod a+x init-containerd.sh
bash init-containerd.sh ${REGISTRY_DOMAIN} ${REGISTRY_PORT}
if [ $? != 0 ]; then
error &amp;#34;====init containerd failed!====&amp;#34;
fi
chmod a+x init-shim.sh
bash init-shim.sh
if [ $? != 0 ]; then
error &amp;#34;====init image-cri-shim failed!====&amp;#34;
fi
chmod a+x init-kube.sh
bash init-kube.sh
logger &amp;#34;init containerd rootfs success&amp;#34;
&lt;/code>&lt;/pre>&lt;p>在 MountRootfs 这步中，只会执行 &lt;code>rootfs&lt;/code> 和 &lt;code>addons&lt;/code> 类型的 &lt;code>init.sh&lt;/code> 脚本。这也很好理解，因为到目前为止，Sealos 仅仅在每台机器上安装成功了 kubelet，整个 k8s 集群还未可用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Init：初始化 k8s 集群。在这步中，其实也是执行了一系列的子操作。&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Sealos 会从 &lt;code>ClusterFile&lt;/code> 中加载 &lt;code>kubeadm&lt;/code> 的配置，然后拷贝到 master0 上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>根据 master0 的 hostname 生成证书以及 k8s 配置文件，例如 &lt;code>admin.conf&lt;/code>，&lt;code>controller-manager.conf&lt;/code>，&lt;code>scheduler.conf&lt;/code>，&lt;code>kubelet.conf&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sealos 将这些配置以及 rootfs 中的静态文件（主要是一些 policy 的配置）拷贝到 master0 上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Sealos 通过 link 的方式将 rootfs 中的 registry 链接到宿主机的目录上，然后执行脚本 &lt;code>init-registry.sh&lt;/code>，启动 registry 守护进程。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>最后也是最重要的，初始化 master0。首先，将 registry 的域名，api server的域名（IP 为 master0 的 IP）添加到 master0 宿主机上。然后，调用 &lt;code>kubeadm init&lt;/code> 创建 k8s 集群。最后，将生成的管理员 kubeconfig 拷贝到 &lt;code>.kube/config&lt;/code>。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Join：使用 kubeadm 将其余 master 和 node 加入现有的集群，然后更新 &lt;code>ClusterFile&lt;/code>。此时，整个 k8s 集群就已经搭建完毕了。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>RunGuest: 运行所有类型为 &lt;code>app&lt;/code> 的镜像的 CMD，安装所有应用。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>至此一个 k8s 集群以及基于这个集群的所有应用都被安装完毕。&lt;/p>
&lt;h4 id="reconcilecluster" class="relative group">reconcileCluster &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#reconcilecluster" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>第二个分支是负责集群的更新，大部分内容与 &lt;code>initCluster&lt;/code> 都比较类似。执行主要包含了以下几步：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>ConfirmOverrideApps: 确认是否覆盖已有的应用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PreProcess, RunConfig, MountRootfs, RunGuest: 都与 &lt;code>initCluster&lt;/code> 类似。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PostProcess: 执行一些安装后的操作，但目前似乎并没有进行任何操作。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="不仅仅如此" class="relative group">不仅仅如此&amp;hellip; &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e4%b8%8d%e4%bb%85%e4%bb%85%e5%a6%82%e6%ad%a4" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>经过上文的介绍，可以看到 Sealos 对于 Kubernetes 生命周期管理有着非常好的抽象，而不只是个简单的安装脚本，你甚至可以扩展其它的 runtime 来支持 k3s k0s 等，而大部分定制化只需要修改集群镜像而不用修改 sealos 的源代码。不仅如此，sealos 还可以让你像使用 PC 操作系统一样用云，各种分布式软件信手拈来，真正让用云的门槛降到足够低。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./1ef54cfebd1c76bc8ecfd9897f9f127107b6e555.png" alt="" />
&lt;/figure>
&lt;/p></description></item><item><title>Casbin is All You Need</title><link>https://blog.abingcbc.cn/posts/casbin/</link><pubDate>Wed, 22 Jun 2022 01:05:51 +0000</pubDate><guid>https://blog.abingcbc.cn/posts/casbin/</guid><description>&lt;h2 id="tldr" class="relative group">TL;DR &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#tldr" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;ul>
&lt;li>访问控制框架 Casbin 的原理以及其内部组件的结构&lt;/li>
&lt;li>以一个 RBAC 的简单例子介绍 Casbin 的用法&lt;/li>
&lt;/ul>
&lt;h2 id="casbin是什么" class="relative group">Casbin是什么？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#casbin%e6%98%af%e4%bb%80%e4%b9%88" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;h3 id="访问控制" class="relative group">访问控制 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e8%ae%bf%e9%97%ae%e6%8e%a7%e5%88%b6" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./2022-06-23-17-50-00-image.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>访问控制，顾名思义，是指判断一条请求是否可以访问受保护的资源的技术。在上图的例子中，我们的后台中有两个资源，Resource1和Resource2。它们可以是服务器、账号、图片、视频等等等等。但是，它们的相同特性是不能被所有用户都访问。比如 Resource1 属于用户 Alice，那么只有 Alice 能够访问它，Bob 则不能。因此，我们就需要对访问请求进行过滤，判断其是否被允许到达目标资源。在上面的例子中，Alice 发起了两个访问请求，分别想要访问 Resource1 和 Resource2。访问控制层需要做的工作就是允许访问 Resource1 的请求通过，而阻拦想要访问 Resource2 的请求，因为 Resource2 属于 Bob，Alice 是无法访问的。&lt;/p>
&lt;p>在实际应用中，访问控制问题往往会随着业务而变得非常复杂。而 Casbin &lt;a
href="#casbin"
>&lt;sup>1&lt;/sup>&lt;/a> 就是一个强大的、高效的开源访问控制框架。Casbin 在 Github 上已获得超过 10k+ star，并且有着非常完整的生态。基于 Casbin 可以轻松的实现一系列访问控制模型，如 RBAC，ABAC等等。&lt;/p>
&lt;h3 id="原理pml" class="relative group">原理——PML &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%8e%9f%e7%90%86pml" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>Casbin 的底层原理基于其创建者罗杨博士所发表的一篇论文《PML: An Interpreter-Based Access Control Policy Language for Web Services》&lt;a
href="#pml"
>&lt;sup>2&lt;/sup>&lt;/a>&lt;/p>
&lt;h4 id="设计目标" class="relative group">设计目标 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e8%ae%be%e8%ae%a1%e7%9b%ae%e6%a0%87" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>这篇论文主要关注于如何解决现实中云服务厂商有关权限校验所遇到的两个问题：&lt;/p>
&lt;ol>
&lt;li>每个云服务厂商都有着自己的一套权限检验规则。这对于在多个云环境都进行部署的用户来说，造成了很大的迁移和维护成本。&lt;/li>
&lt;li>同样的，维护自己的一套权限校验规则对于云服务厂商来说，也是一个挑战。如果云服务厂商缺乏在这方面的相关经验，就很有可能造成安全漏洞。&lt;/li>
&lt;/ol>
&lt;p>既然文章的目标本质上是通过通用性来解决问题，作者也考虑了如何实现这个目标，提出了两个 independent 的设计要求：&lt;/p>
&lt;ol>
&lt;li>Access Control Model Independent：PML 既需要支持用户可以在多个云服务厂商中使用同一个模型，也需要支持用户在不改变校验代码的同时，可以切换不同的模型。&lt;/li>
&lt;li>Implementation Language Independent: PML 的设计不应该依赖于某种编程语言的特性。
因此，文中提出了一种新的权限校验语言——PML (PERM Modeling Language)，希望通过一种支持多种权限校验模型的配置语言来弥补这个 gap。&lt;/li>
&lt;/ol>
&lt;h4 id="设计实现" class="relative group">设计实现 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e8%ae%be%e8%ae%a1%e5%ae%9e%e7%8e%b0" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>在介绍 PML 的设计之前，我们可以先大致了解一下访问控制问题中，所涉及到的一些概念。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./overview.png" alt="1c2dea1652f67c0b7920b0471a4113afd8d9325a.png" />
&lt;/figure>
&lt;/p>
&lt;p>一般来说，访问控制会涉及到两个部分：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Model 访问控制模型&lt;/strong>。常见的模型有 ACL（Access Control List 访问控制列表），RBAC（Role-Based Access Control 基于角色的访问控制），ABAC（Attribute-Based Access Control 基于属性的访问控制）。对于一个应用来说，Model 的选择是与应用的业务逻辑是密切相关的，因此也是相对静态的。一旦代码编译完成，这部分是不会随着应用的运行而产生变化的。&lt;/li>
&lt;li>&lt;strong>Policy 访问控制规则&lt;/strong>。Policy 是和 Model 相对应的，每种不同的 Model，都会有不同格式的 Policy。而与 Model 完全相反的是，Policy 是相对动态的。在编写代码的过程中，我们只能去定义 Policy 的格式，而 Policy 的具体内容都是应用运行过程中添加或修改的。例如，有一个新用户注册了我们的应用。那么，我们就需要动态的为其添加一条 Policy。&lt;/li>
&lt;/ol>
&lt;p>我们可以将这两部分理解为传统应用中的代码和数据。有了这两部分后，再加上用户特定的校验逻辑，那么就可以完成访问控制任务。&lt;/p>
&lt;h5 id="perm-模型" class="relative group">PERM 模型 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#perm-%e6%a8%a1%e5%9e%8b" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h5>
&lt;p>当然，对于现实环境中复杂的情况，简单地将问题建模为这两部分肯定是不够的，因此，论文提出了一个新的元模型 PERM（Policy-Effect-Request-Matcher）。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./pml.png" alt="6d8fa0a037c3ea185cfadb8d817c41cce0d66d78.png" />
&lt;/figure>
&lt;/p>
&lt;p>PERM 模型主要包含了 6 个主要的概念：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Request&lt;/strong>：访问请求定义。用户真实的访问请求，通常会包含 sub（访问者），obj（被访问的资源）， act（访问时所进行的操作）或其他用户自定义的属性。&lt;/li>
&lt;li>&lt;strong>Policy&lt;/strong>：访问控制规则定义。定义了需要对访问请求的哪些属性进行校验。&lt;/li>
&lt;li>&lt;strong>Policy Rule&lt;/strong>：访问控制规则实例。&lt;/li>
&lt;li>&lt;strong>Matcher&lt;/strong>：如何为一条 Request 匹配到其对应的 Policy Rule。&lt;/li>
&lt;li>&lt;strong>Effect&lt;/strong>：当一条 Request 匹配到了一条或多条 Policy Rule，如何判断其是否应该被允许。&lt;/li>
&lt;li>&lt;strong>Stub Function&lt;/strong>：在实际应用中，Request 实例 和 Policy Rule 的匹配往往无法通过简单的 == 等于来解决，例如通配符等等。所以 Stub Function 允许用户自定义一些复杂的匹配方法。&lt;/li>
&lt;/ol>
&lt;p>这六个更加详细的建模了访问控制的问题。我们也可以对其简单的分一下类，Request，Policy，Matcher，Effect 和 Stub Function 都是静态的，属于 Model 的一部分。通过这个五项的组合，ACL等常见的模型以及一些用户自定义的规则，都可以很轻易的表示出来。在最后一部分中，会以 RBAC 为例，介绍如何通过 PML 实现这样一个模型。&lt;/p>
&lt;p>而 Policy Rule 就属于动态变化的内容。在实际实现中，往往也是像数据一样，存储在数据库当中的。&lt;/p>
&lt;h2 id="结构" class="relative group">结构 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e7%bb%93%e6%9e%84" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>与论文中的实现相比，目前 Casbin 的实现更加强大，支持了更多功能。所以，这里以 Casbin 主库（Go 版本），介绍 Casbin 是如何进行工作的。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./detail.png" alt="6dbf7fb95022569c5ad99becdcd9090df8a99250.png" />
&lt;/figure>
&lt;/p>
&lt;ol>
&lt;li>
&lt;p>在应用启动时，Casbin 会读取用户已经定义好的 Model，其中会包含 Request, Policy, Matcher 和 Effector 四个部分的定义。同时，Casbin 会利用 Adapter，从数据源处读取 Policy 实例（也就是上文提到的 Policy Rule）。后文就将 Policy 实例简称为 Policy。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对于 Policy 的存储和读取，Casbin 将其解耦到了独立的 Adapter 模块。通过使用不同的 Adapter（File, MySQL等等），可以从不同的数据源中读取 Policy。对于 Policy 比较多的场景，将所有的 Policy 同时加载进内存，确实会导致一定的性能损失。所以，在加载时，部分 Adapter 也提供 &lt;code>LoadFilteredPolicy&lt;/code> 的接口，通过只加载 Policy 的一部分子集，减少这部分带来的性能瓶颈。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在一条请求到来时，该请求首先会按照 Model 中的定义进行拆分。接下来，Matcher 会根据 Model 中定义的规则，与 Policy 进行匹配。除了支持 == 强匹配外，Matcher 还支持通过 Function 和 Role Manager 进行模糊匹配。Function 像用户提供了自定义匹配规则的接口。通过向 Matcher 传入自定义函数，Matcher 可以对 Request 与 Policy 之间进行一些复杂的匹配。&lt;/p>
&lt;p>对于 RBAC 等访问控制模型，除了单纯的用户与权限之间存在关系之外，用户与角色（Role）之间还存在着继承关系。Casbin 中采用了 Role Manager 来为一条 Request 的用户以及其对应角色（包含继承角色）寻找与其相关的 Policy。同时，Role Manager 也支持添加自定义的 Function，来对用户与角色之间进行复杂的匹配。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在实际应用中，一条 Request 可能会匹配到多条 Policy。得到所有的 Policy 后，需要进一步将多条 Policy 的结果进行聚合，得到最终是否允许 Request。Effector 根据 Model 中配置的规则，对所有 Matched Policy 的 effect 项进行进一步的 eval。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在很多场景下，访问控制服务会有多个实例。Casbin 支持对 Policy 进行增量更新，那么，就需要 Dispatcher 维护多个 Casbin 实例的 Policy 之间的一致性。Dispatcher 主要提供两部分的功能，一部分是 Casbin 的 API，另一部分是 Dispatcher 自身的 API，用来实现成员管理等一致性问题，可以通过 Raft 等共识算法实现。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="usage" class="relative group">Usage &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#usage" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>在了解了 Casbin 的原理和结构后，我们可以开始利用 Casbin 来进行一些实践。本章以 RBAC 模型为例，构建一个简单的访问控制示例。RBAC (Role-Based Access Control) 模型是基于角色的访问控制模型。在 RBAC 的模型中，用户和资源之间存在着角色（Role），用户可以属于一个或多个角色，角色拥有权限去访问资源。&lt;/p>
&lt;p>经过前两章的介绍，我们可以将访问控制分为三个部分：Static，Dynamic 和 User-specific Logic。在使用 Casbin 时，也可以这样进行划分。首先，我们先来定义一个静态的 RBAC Model（model.conf）。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-c#" data-lang="c#">&lt;span class="line">&lt;span class="cl">&lt;span class="na">[request_definition]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">r&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="n">sub&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">act&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">[policy_definition]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">p&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="n">sub&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">obj&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">act&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">[role_definition]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">g&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="n">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">[policy_effect]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">e&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="n">some&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">where&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">p&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">eft&lt;/span> &lt;span class="p">==&lt;/span> &lt;span class="n">allow&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="na">[matchers]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">m&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">r&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">sub&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">sub&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">r&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">obj&lt;/span> &lt;span class="p">==&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">obj&lt;/span> &lt;span class="p">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">r&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">act&lt;/span> &lt;span class="p">==&lt;/span> &lt;span class="n">p&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">act&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>在这个模型中，分别定义了五部分内容。&lt;/p>
&lt;ol>
&lt;li>&lt;strong>request_definition&lt;/strong>，定义了 Request 的结构。这份示例中包含了访问者（sub），被访问者（obj）和操作（act）。&lt;/li>
&lt;li>&lt;strong>policy_definition&lt;/strong>，定义了 Policy 的结构。通常，由于 Policy 和 Request 之间要进行匹配，所以两者的结构有一定的相似性。&lt;/li>
&lt;li>&lt;strong>role_definition&lt;/strong>，定义了 Role Manager。&lt;code>g&lt;/code> 定义了一套 RBAC 系统，换句话说是一组用户角色继承关系的集合。在实际使用中，更类似于一个函数，判断输入的参数是否在这个集合中存在继承关系。&lt;/li>
&lt;li>&lt;strong>policy_effect&lt;/strong>，定义了如何对多个匹配到的 Policy 做合并。目前，Casbin 支持几个固定语法的合并模式，在官网 &lt;a
href="#policy"
>&lt;sup>3&lt;/sup>&lt;/a> 上有着详细的介绍。这些模式的含义也很好理解，模式的语法与自然语言或者 SQL 非常相近。例如，&lt;code>some(where (p.eft == allow))&lt;/code> 表示的是当任意一个 Policy 的 effect 是 allow，那么合并的结果即为 allow。&lt;/li>
&lt;li>&lt;strong>matchers&lt;/strong>，定义了如何匹配 Policy 和 Request。 定义公式的语法与常见语言中的布尔表达式相似，通过 &lt;code>==&lt;/code> 可以将 Policy 和 Request 中的各项进行对比。&lt;/li>
&lt;/ol>
&lt;h4 id="policy" class="relative group">Policy &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#policy" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;pre tabindex="0">&lt;code>p, alice, data1, read
p, bob, data2, write
p, data2_admin, data2, read
p, data2_admin, data2, write
g, alice, data2_admin
&lt;/code>&lt;/pre>&lt;p>接下来，我们可以按照 Model 中定义的 Policy 结构来编写 Policy 实例。例如，第一项 &lt;code>p, alice, data1, read&lt;/code> 与 &lt;code>p = sub, obj, act&lt;/code> 相对应，&lt;code>alice&lt;/code>，&lt;code>data1&lt;/code>，&lt;code>read&lt;/code> 与 &lt;code>sub&lt;/code>，&lt;code>obj&lt;/code>，&lt;code>act&lt;/code> 相对应。另外一条比较特殊的实例是最后一项，&lt;code>g, alice, data2_admin&lt;/code>，定义了用户 &lt;code>alice&lt;/code> 继承了 &lt;code>data2_admin&lt;/code> 这一角色。&lt;/p>
&lt;p>我们可以将上面的 Policy 保存在文件 policy.csv 中。但一般来说，Policy 储存在数据库等等一些更加 organized 的外部存储中。&lt;/p>
&lt;h4 id="user-logic" class="relative group">User Logic &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#user-logic" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>Casbin 几乎支持所有的常见的编程语言，用户使用的逻辑也基本相似，主要通过 Enforcer 类来进行操作。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-go" data-lang="go">&lt;span class="line">&lt;span class="cl">&lt;span class="nx">e&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">err&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">casbin&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">NewEnforcer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;model.conf&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;policy.csv&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">result1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">_&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">e&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Enforce&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;alice&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;data1&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">fmt&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Println&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">result1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">result2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">_&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">e&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Enforce&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;alice&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;data1&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;write&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">fmt&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Println&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">result2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">result3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">_&lt;/span> &lt;span class="o">:=&lt;/span> &lt;span class="nx">e&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Enforce&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;alice&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;data2&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s">&amp;#34;read&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nx">fmt&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nf">Println&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">result3&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>通过 Enforce 方法，开发者输入 Request，就可以得到这条请求是否可以通过。在上述例子中有 3 个 test case，分别验证了合法请求匹配，非法请求匹配，集成角色请求匹配。第一个 test case 对应了 policy.csv 中的第一条 Policy，第二个 test case 则没有 test case。第三个 test case 通过 &lt;code>g, alice, data2_admin&lt;/code> 将 alice 与 data2_admin 的 Policy 关联起来，然后通过第三条 Policy p, data2_admin, data2, read 验证其为合法请求。&lt;/p>
&lt;h2 id="reference" class="relative group">Reference &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#reference" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;div id="ref1"/>
- [1] https://github.com/casbin/casbin
&lt;div id="ref2"/>
- [2] https://arxiv.org/pdf/1903.09756.pdf
&lt;div id="ref3"/>
- [3] https://casbin.org/docs/en/syntax-for-models#policy-effect</description></item><item><title>Kubernetes is All You Need</title><link>https://blog.abingcbc.cn/posts/k8s-ramp-up/</link><pubDate>Mon, 15 Mar 2021 15:39:36 +0000</pubDate><guid>https://blog.abingcbc.cn/posts/k8s-ramp-up/</guid><description>&lt;h2 id="目标" class="relative group">目标 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e7%9b%ae%e6%a0%87" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;ul>
&lt;li>介绍 K8s，Docker 概念以及原理&lt;/li>
&lt;li>从 0 开始部署一个简单完整的服务&lt;/li>
&lt;/ul>
&lt;h2 id="docker是什么" class="relative group">Docker是什么？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#docker%e6%98%af%e4%bb%80%e4%b9%88" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>Docker是由Google推出的Go语言进行开发实现，基于Linux内核的 &lt;font color=red>namespace&lt;/font>，对&lt;font color=red>进程&lt;/font>进行封装&lt;font color=red>隔离&lt;/font>，属于操作系统层面的容器化技术。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./1.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;h3 id="三大核心概念" class="relative group">三大核心概念 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e4%b8%89%e5%a4%a7%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>镜像（Image）&lt;/p>
&lt;p>容器（Container）&lt;/p>
&lt;p>仓库（Repository）&lt;/p>
&lt;p>从代码的角度来看，镜像就像一个类；容器是对象实例，运行时在系统中会有许多容器；仓库主要用于存储和维护这些镜像。&lt;/p>
&lt;h3 id="为什么使用-docker" class="relative group">为什么使用 Docker？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bd%bf%e7%94%a8-docker" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;ul>
&lt;li>配置环境
开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性&lt;/li>
&lt;li>应用隔离
机器上可能同时运行多个服务。如果服务之间没有隔离，一个服务出现异常，往往可能会导致其他服务也挂掉。同时，不同服务所依赖的环境也可能发生冲突。&lt;/li>
&lt;/ul>
&lt;h3 id="原理" class="relative group">原理 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%8e%9f%e7%90%86" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>首先，要了解一下进程的命名空间。Linux 系统中的所有进程按照惯例是通过PID标识的，这意味着内核必须管理一个全局的PID列表。而且，所有调用者通过uname系统调用返回的系统相关信息（包括系统名称和有关内核的一些信息）都是相同的。&lt;/p>
&lt;p>Linux 的命名空间从内核层面上进行了虚拟化，对所有的全局资源进行一个抽象。本质上，建立了系统的不同视图。每一项全局资源都必须包装到命名空间的数据结构中，只有资源和包含资源的命名空间构成的二元组仍然是全局唯一的。不仅仅是 PID，Linux 通过同样的方法对其他资源也做了虚拟化处理。命名空间共有以下6种：&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./2.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>借助 Linux 的命名空间，Docker 对进程进行隔离，可以从进程树的角度理解。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./3.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>每次在执行 &lt;code>docker start&lt;/code> 或 &lt;code>docker run&lt;/code> 的时候，其实是由 docker 的 daemon 进程 docker containerd，调用 Linux 系统调用 &lt;code>clone()&lt;/code> 去创建新的进程。而创建进程的过程中就为新创建的进程分配了新的 Linux 命名空间。可以简单阅读一下 docker 的开源代码&lt;/p>
&lt;pre>&lt;code class="go">// https://github.com/moby/moby/blob/49e809fbfe250f3df2deacc0c3e5c403db3b8915/daemon/start.go#L17
// 创建容器的函数，其中又调用了设置
func (daemon *Daemon) ContainerStart(name string, hostConfig *containertypes.HostConfig, checkpoint string, checkpointDir string) error
// https://github.com/moby/moby/blob/470ae8422fc6f1845288eb7572253b08f1e6edf8/daemon/oci_linux.go#L212
// 设置 Namespace
func setNamespace(s *specs.Spec, ns specs.LinuxNamespace) {
for i, n := range s.Linux.Namespaces {
if n.Type == ns.Type {
s.Linux.Namespaces[i] = ns
return
}
}
s.Linux.Namespaces = append(s.Linux.Namespaces, ns)
}
// https://github.com/moby/moby/blob/49e809fbfe250f3df2deacc0c3e5c403db3b8915/daemon/start.go#L198
// 创建新的进程
pid, err := daemon.containerd.Start(context.Background(),
container.ID,
checkpointDir,
container.StreamConfig.Stdin() != nil | | container.Config.Tty,
container.InitializeStdio)
&lt;/code>&lt;/pre>
&lt;h3 id="如何安装" class="relative group">如何安装？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%a6%82%e4%bd%95%e5%ae%89%e8%a3%85" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>&lt;a
href="https://docs.docker.com/get-docker/"
target="_blank" rel="noreferrer noopener"
>https://docs.docker.com/get-docker/&lt;/a>&lt;/p>
&lt;h2 id="kubernetes是什么" class="relative group">Kubernetes是什么？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#kubernetes%e6%98%af%e4%bb%80%e4%b9%88" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>Kubernetes 是 Google 于 2014 年基于其内部 Brog 系统开源的一个容器编排管理系统，可使用声明式的配置（以 yaml 文件的形式）自动地执行容器化应用程序的管理，包括部署、伸缩、负载均衡、回滚等。&lt;/p>
&lt;p>为什么叫 K8s？因为 K&lt;font color=red>ubernete&lt;/font>s，中间是8个字母。&lt;/p>
&lt;p>kubernetes 提供的功能：&lt;/p>
&lt;ul>
&lt;li>自动发布与伸缩：可以通过声明式的配置文件定义想要部署的容器&lt;/li>
&lt;li>滚动升级与灰度发布：采用逐步替换的策略实现滚动升级&lt;/li>
&lt;li>服务发现与负载均衡：Kubernetes 通过 DNS 名称或 IP 地址暴露容器的访问方式，并且可在同一容器组内实现负载分发与均衡&lt;/li>
&lt;li>存储编排：Kubernetes 可以自动挂载指定的存储系统，如 local storage/nfs / 云存储等&lt;/li>
&lt;li>故障恢复：Kubernetes 自动重启已经停机的容器，替换不满足健康检查的容器&lt;/li>
&lt;li>密钥与配置管理：Kubernetes 可以存储与管理敏感信息，如 Docker Registry 的登录凭证，密码，ssh 密钥等&lt;/li>
&lt;/ul>
&lt;h3 id="为什么使用-k8s" class="relative group">为什么使用 K8s？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e4%bd%bf%e7%94%a8-k8s" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>大型单体应用被逐渐拆分成小的、可独立运行的组件。随着部署组件的增多和数据中心的增长，配置、管理和运维变得很困难。(微服务）&lt;/p>
&lt;p>K8s 的定义就是容器编排和管理引擎，解决了这些问题。&lt;/p>
&lt;h3 id="如何安装-1" class="relative group">如何安装？ &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%a6%82%e4%bd%95%e5%ae%89%e8%a3%85-1" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>由难到易(๑•̀ㅂ•́)و✧&lt;/p>
&lt;ul>
&lt;li>Kubeadm: &lt;a
href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/"
target="_blank" rel="noreferrer noopener"
>https://kubernetes.io/docs/reference/setup-tools/kubeadm/&lt;/a>&lt;/li>
&lt;li>MiniKube: Local kubernetes &lt;a
href="https://minikube.sigs.k8s.io/docs/start/"
target="_blank" rel="noreferrer noopener"
>https://minikube.sigs.k8s.io/docs/start/&lt;/a>&lt;/li>
&lt;li>Kind: Kubernetes in Docker &lt;a
href="https://github.com/kubernetes-sigs/kind"
target="_blank" rel="noreferrer noopener"
>https://github.com/kubernetes-sigs/kind&lt;/a>&lt;/li>
&lt;li>Docker-desktop（仅限 Mac）: 一键开启
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./4.png" alt="" />
&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;p>其他版本的类 K8s 系统：&lt;/p>
&lt;ul>
&lt;li>K3s: &lt;a
href="https://github.com/k3s-io/k3s"
target="_blank" rel="noreferrer noopener"
>https://github.com/k3s-io/k3s&lt;/a>&lt;/li>
&lt;li>K0s: &lt;a
href="https://github.com/k0sproject/k0s"
target="_blank" rel="noreferrer noopener"
>https://github.com/k0sproject/k0s&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="kubernetes-架构" class="relative group">Kubernetes 架构 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#kubernetes-%e6%9e%b6%e6%9e%84" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./5.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;h3 id="master" class="relative group">master &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#master" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>Master 负责管理服务来对整个系统进行管理与控制，包括&lt;/p>
&lt;ul>
&lt;li>apiserver：作为整个系统的对外接口，提供一套 Restful API 供客户端调用，任何的资源请求 / 调用操作都是通过 kube-apiserver 提供的接口进行, 如 kubectl、kubernetes dashboard 等管理工具就是通过 apiserver 来实现对集群的管理&lt;/li>
&lt;li>kube-scheduler：资源调度器，负责将容器组分配到哪些节点上&lt;/li>
&lt;li>kube-controller-manager：管理控制器，集群中处理常规任务的后台线程，包括节点控制器（负责监听节点停机的事件并作出对应响应）、endpoint-controller（刷新服务与容器组的关联信息）、replication-controller（维护容器组的副本数为指定的数值）、Service Account &amp;amp; Token 控制器（负责为新的命名空间创建默认的 Service Account 以及 API Access Token）&lt;/li>
&lt;li>etcd：数据存储，存储集群所有的配置信息&lt;/li>
&lt;li>coredns：实现集群内部通过服务名称进行容器组访问的功能&lt;/li>
&lt;/ul>
&lt;h3 id="worker" class="relative group">worker &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#worker" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>Worker 负载执行 Master 分配的任务，包括&lt;/p>
&lt;ul>
&lt;li>kubelet：是工作节点上执行操作的代理程序，负责容器的生命周期管理，定期执行容器健康检查，并上报容器的运行状态&lt;/li>
&lt;li>kube-proxy：是一个具有负载均衡能力的简单的网络访问代理，负责将访问某个服务的请求分配到工作节点的具体某个容器上（kube-proxy 也运行于 master node 上）&lt;/li>
&lt;li>Docker Daemon：Kubernetes 其实不局限于 Docker（即将取消），它支持任何实现了 Kubernetes 容器引擎接口的容器引擎，如 containerd、rktlet&lt;/li>
&lt;/ul>
&lt;h3 id="网络通信" class="relative group">网络通信 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e7%bd%91%e7%bb%9c%e9%80%9a%e4%bf%a1" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>网络通信组件只需要符合 CNI （Container Network Interface）接口规范，主要作用在于给各个容器分配集群内 IP，使得其内网 IP 能够集群内唯一，并且可以互相访问，目前常用的有 Flannel，Calico等网络组件。&lt;/p>
&lt;p>简单介绍下比较常用的 Flannel 的原理。Flannel 运行在第3层网络层，基于 IPv4，创建一个大型内部网络，跨越集群中每个节点。每个节点组成一个子网，每个容器在内网中有唯一的IP。&lt;/p>
&lt;p>首先，Flannel 会为每台节点分配一个子网段。Flanneld 在 Docker 容器启动时修改其启动参数，将其 IP 限制在当前的子网段内，具体 IP 的分配仍是由 docker 进行。Flannel通过Etcd服务维护了一张节点间的路由表，详细记录了各节点子网网段，保证不同节点的子网网段不会重复。&lt;/p>
&lt;p>数据从源容器中发出后，经由所在主机的docker0虚拟网卡转发到flannel0虚拟网卡，flanneld服务监听在网卡的另外一端。&lt;/p>
&lt;p>源主机的flanneld服务将原本的数据内容UDP封装后根据自己的路由表投递给目的节点的flanneld服务，数据到达以后被解包，然后直接进入目的节点的flannel0虚拟网卡，然后被转发到目的主机的docker0虚拟网卡，最后就像本机容器通信一下的有docker0路由到达目标容器。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./6.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;h2 id="快速上手-k8s-概念" class="relative group">快速上手 K8s 概念 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%bf%ab%e9%80%9f%e4%b8%8a%e6%89%8b-k8s-%e6%a6%82%e5%bf%b5" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>一些推荐的 K8s 概念介绍：&lt;/p>
&lt;ul>
&lt;li>微软的 50天 K8s 教程中（https://azure.microsoft.com/en-us/resources/kubernetes-learning-path/）通过动物园的形式介绍了一些 K8s 概念 &lt;a
href="http://aka.ms/k8s/LearnwithPhippy"
target="_blank" rel="noreferrer noopener"
>http://aka.ms/k8s/LearnwithPhippy&lt;/a>&lt;/li>
&lt;li>综述PPT：https://www2.slideshare.net/BobKillen/kubernetes-a-comprehensive-overview-updated?from_action=save&lt;/li>
&lt;/ul>
&lt;p>K8s 中的概念极多，比较零碎，这里通过一个简单的小例子，尽可能覆盖多的 K8s 概念。&lt;/p>
&lt;h2 id="概览" class="relative group">概览 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e6%a6%82%e8%a7%88" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;p>例子使用一个开源的 fortune-teller 镜像（&lt;code>quay.io/kubernetes-ingress-controller/grpc-fortune-teller:0.1&lt;/code>） ，每次请求容器内的服务，服务会返回一句名言。希望在 MacOS 的环境下，展示一个应用在 K8s 中运行的全流程。&lt;/p>
&lt;p>准备环境
为了不影响大家本地的环境，这里使用 Kind 创建出一个独立的 K8s 集群，方便统一版本并且可以在完成快速清理掉。(Docker 双重隔离）&lt;/p>
&lt;ol>
&lt;li>安装 Kind 以及 gRpc 测试工具&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">brew install kind
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">brew install grpcurl
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>拉取镜像&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">docker pull kindest/node:v1.16.15
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker pull quay.io/kubernetes-ingress-controller/grpc-fortune-teller:0.1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>创建 K8s 集群，因为 Kind 是在 Docker 容器里面创建的 K8s，所以宿主机访问，需要把端口暴露出来。Kind 会默认把 K8s apiserver 的端口暴露出来，用来给 kubectl 命令使用。但为了之后的测试，我们提前把几个端口在创建的时候就暴露出来。&lt;/li>
&lt;/ol>
&lt;p>Kind 同样支持通过yaml 的形式创建集群&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Cluster&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">kind.x-k8s.io/v1alpha4&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">nodes&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>- &lt;span class="nt">role&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">control-plane&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">extraPortMappings&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">containerPort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">32080&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">hostPort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">32080&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">containerPort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">32443&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">hostPort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">32443&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">kind create cluster --name&lt;span class="o">=&lt;/span>fortune-teller --image&lt;span class="o">=&lt;/span>kindest/node:v1.16.15 --config kind-config.yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="运行-docker-版本" class="relative group">运行 Docker 版本 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e8%bf%90%e8%a1%8c-docker-%e7%89%88%e6%9c%ac" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;ol>
&lt;li>启动容器&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">docker run -p 50051:50051 quay.io/kubernetes-ingress-controller/grpc-fortune-teller:0.1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>-p&lt;/code> 将容器内的 50051 端口映射到宿主机的 50051 端口&lt;/p>
&lt;ol start="2">
&lt;li>测试应用是否正常运行，第一次运行时可能需要给 grpcurl 开启权限&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">grpcurl -plaintext 127.0.0.1:50051 build.stack.fortune.FortuneTeller/Predict
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>应用在收到请求以后，会返回一句名言&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./7.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;h3 id="将应用从-docker-迁移到-k8s-中" class="relative group">将应用从 Docker 迁移到 K8s 中 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%b0%86%e5%ba%94%e7%94%a8%e4%bb%8e-docker-%e8%bf%81%e7%a7%bb%e5%88%b0-k8s-%e4%b8%ad" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h3>
&lt;p>与 Docker 中容器概念相对应的，K8s 中也有着容器的概念。对于虚拟化的容器来说，最佳实践是一个容器一个应用，但当一个服务需要多个应用组合完成时，简单的将多个应用部署到一个容器内，就破坏了应用之间的隔离性，所以 K8s 对于容器进行了一层封装，形成了 Pod 的概念。&lt;/p>
&lt;h4 id="pod" class="relative group">Pod &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#pod" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>Pod 是 Kubernetes 创建或部署的最小基本单元。一个 Pod 封装一个或多个应用容器、存储资源、一个独立的网络 IP 以及管理控制容器运行方式的策略选项。Pod 中的每个容器共享网络命名空间（包括 IP 与端口），Pod 内的容器可以使用 localhost 相互通信。Pod 可以指定一组共享存储卷 Volumes，Pod 中所有容器都可以访问共享的 Volumes。&lt;/p>
&lt;p>通过 Pod，用户就可以非常方便地控制容器之间的隔离性。&lt;/p>
&lt;p>有了 Pod 作为基础以后，K8s 就要实现它最重要的功能，对容器的编排管理。当服务需要扩容时，K8s 需要能够快速复制 Pod，当 Pod 挂掉了，K8s 需要能够自动重启。所以 K8s 由此衍生出了 ReplicaSet 的概念。&lt;/p>
&lt;h4 id="replicaset" class="relative group">ReplicaSet &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#replicaset" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>ReplicaSet 确保在任何时候都有按配置的 Pod 副本数在运行，通过标签选择器的方式对 Pod 进行筛选和管理。在旧的版本中还有一个 ReplicaController 的概念，RC 与 RS 两者功能完全相同，区别仅仅在于 RS 对于 Pod 的标签选择器更加强大。&lt;/p>
&lt;p>开头提到了 K8s 使用声明式的配置自动去管理容器，而 ReplicaSet 的内容却太过具体，涉及到了 Pod 的具体维护细节。所以 K8s 在 ReplicaSet 之上又衍生出声明式配置容器的概念，Deployment。&lt;/p>
&lt;h4 id="deployment" class="relative group">Deployment &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#deployment" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>Deployment 为 Pod 与 ReplicaSet 提供了声明式的定义，描述你想要的目标状态是什么，Deployment controller 就会帮你将 Pod 与 ReplicaSet 的实际状态改变到你想要的目标状态。&lt;/p>
&lt;p>以 fortune-teller 为例子，可以编写一份下面这样的 Deployment 配置文件&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">apps/v1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># k8s api版本&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Deployment&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># 资源类型&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-app&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># deployment 名字&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">namespace&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">default&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">replicas&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">1&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Pod 副本数量&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">selector&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">matchLabels&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">k8s-app: fortune-teller-app # 管理标签中包含 k8s-app&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-app 的 Pod&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">template&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Pod 模板&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">labels&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">k8s-app&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-app&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Pod 标签&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Pod 配置&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">containers&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">image&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">quay.io/kubernetes-ingress-controller/grpc-fortune-teller:0.1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">imagePullPolicy&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">IfNotPresent&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-app&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">ports&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">containerPort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">50051&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">grpc&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">protocol&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">TCP&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>将上面的内容保存到一份 yaml 文件中，执行以下命令，让 K8s 执行 yaml&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">kubectl apply -f deployment.yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>通过以下命令，我们就可以看到刚刚创建的 deployment&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">kubectl get deployement
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./8.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>此时，K8s 已经自动根据 deployment 中配置的 Pod 模板和配置，创建了 Pod。通过以下命令，我们就可以看到 K8s 自动创建的 Pod&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">kubectl get pods
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./9.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>因为 K8s 采用声明式的配置去管理 Pod，所以我们可以动态地去修改 deployment 的配置，K8s 会自动根据新的配置去管理 Pod。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">kubectl edit deployment fortune-teller-app
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们把配置文件中的副本数量修改为 2&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./10.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>保存退出后，我们再次执行 kubectl get pods ，我们就可以看到 K8s 根据新的配置，创建了一个新的 Pod&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./11.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>现在我们就有了两个 fortune-teller 的服务。在真实环境中，Pod 的调度由 K8s 进行管理，某个时刻服务可能在 Node1 上，而另一时刻服务可能就被调度到了 Node2 上。所以，访问具体 Pod 是一种不稳定的服务访问方法，而且目前大多数的后端服务都是无状态的服务，直接访问 Pod 也导致不能进行负载均衡。所以，K8s 在此基础上衍生出 Service 的概念。&lt;/p>
&lt;h4 id="service" class="relative group">Service &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#service" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>Service 可以看做一组提供相同服务的 Pod 的对外访问接口。Kubernetes 提供三种类型的 Service：&lt;/p>
&lt;ul>
&lt;li>NodePort： 集群外部可以通过 Node IP 与 Node Port 来访问具体某个 Pod，每台机器上都会暴露同样的端口&lt;/li>
&lt;li>ClusterIP：指通过集群的内部 IP 暴露服务，服务只能够在集群内部可以访问，这也是默认的 ServiceType&lt;/li>
&lt;li>ExternalName：不指向 Pod，指向外部服务
Service 和 Deployment 是一对比较容易混淆的概念，两者都是对一组 Pod 进行管理，但它们两者之间的关系可以用下面这张图来概括&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./12.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>Service 是面向服务调用者，也就是外部访问 K8s。而 Deployment 是面向 K8s 底层引擎的，面向内部管理者。&lt;/p>
&lt;p>Service 的配置文件格式与 Deployment 很类似&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">v1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Service&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-service&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">namespace&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">default&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">ports&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">grpc&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">port&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">50051&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">protocol&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">TCP&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">targetPort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">50051&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">selector&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">k8s-app&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-app&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">ClusterIP&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>同样的，我们通过 kubectl apply -f service.yaml 命令，可以创建 Service。通过 kubectl get service 可以查看到刚刚创建的 Service。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./13.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>接下来，我们登陆到一个 Pod 里去测试一下是否可以访问服务。
Netshoot 镜像中包含了一些网络测试的工具，我们可以直接进入一个 netshoot 容器内测试。采用 deployment 的方式创建 Pod&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">apps/v1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Deployment&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">netshoot&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">namespace&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">default&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">replicas&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">selector&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">matchLabels&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">k8s-app&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">netshoot&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">template&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">labels&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">k8s-app&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">netshoot&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">containers&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">args&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">1000d&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">command&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">/bin/sleep&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">image&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">nicolaka/netshoot&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">netshoot&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>与 Docker 的命令类似，使用命令 &lt;code>kubectl cp grpcurl_1.6.0_linux_x86_64.tar.gz &amp;lt;pod name&amp;gt;:/&lt;/code> 复制工具到容器内。&lt;/p>
&lt;p>复制成功后，使用命令 kubectl exec -it &lt;pod name> bash 可以进入到容器内。&lt;/p>
&lt;p>解压&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> /
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">tar -zxf grpcurl_1.6.0_linux_x86_64.tar.gz
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后我们可以测试是否可以从 K8s 集群内访问 Service。对于 K8s 集群内部的服务，K8s 有自己的 DNS 组件，所以可以直接通过服务名访问。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">./grpcurl -plaintext fortune-teller-service:50051 build.stack.fortune.FortuneTeller/Predict
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./14.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>验证服务可以从集群内访问之后，我们就需要解决如何从集群外访问服务的问题，毕竟大多数服务是面向 K8s 集群外的用户的。其实目前我们已经了解了一种解决方案，就是使用 Nodeport 类型的 Service。但采用这种方法有几个缺点：&lt;/p>
&lt;ol>
&lt;li>每个端口只能是一种服务&lt;/li>
&lt;li>端口范围只能是 30000-32767&lt;/li>
&lt;li>如果节点 的 IP 地址发生变化，调用方需要能够察觉。
所以，K8s 为服务的外部访问路由提供了新的类型 Ingress。&lt;/li>
&lt;/ol>
&lt;h4 id="ingress" class="relative group">Ingress &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#ingress" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>Ingress 其实是一种类似于路由表一样的配置，实际的路由工作需要 Ingress Controller 执行。K8s 本身并没有提供 Ingress Controller，目前常用的是通过 Nginx 实现的版本 &lt;a
href="https://github.com/kubernetes/ingress-nginx"
target="_blank" rel="noreferrer noopener"
>https://github.com/kubernetes/ingress-nginx&lt;/a> 。可以使用上面压缩包中的 ingress-controller.yaml 安装&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./15.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>Ingree nginx controller 通过宿主机暴露给外部访问的端口是随机的，所以我们修改 yaml，改成我们在一开始创建集群时映射的端口。&lt;/p>
&lt;p>通过 &lt;code>kubectl get svc -n ingress-nginx&lt;/code> 我们就可以看到，暴露的是两个随机分配的端口&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./16.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>我们手动将其改成 32080 和 32443。&lt;/p>
&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./17.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>Ingress nginx controller 同样是通过标签选择器的方式管理 Ingress。&lt;/p>
&lt;p>下面是一个简单的 Ingress，将发往 Host fortune.bytedance.com 的请求路由到 Service fortune-teller-service。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">extensions/v1beta1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Ingress&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">annotations&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">nginx.ingress.kubernetes.io/backend-protocol&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GRPC&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-ingress&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">namespace&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">default&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">rules&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">host&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune.bytedance.com&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">http&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">paths&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">backend&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">serviceName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-service&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">servicePort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">grpc&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>安装 Ingress&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">kubectl apply -f ingress.yaml
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">kubectl get ingress
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./18.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>Ingress nginx controller 对于 gRpc 默认只支持 SSL 的形式，而Fedlearner 中的 controller 做了一些定制化操作，使得通过 80 端口，只使用 HTTP2 也可以转发 gRpc。详情可以参考 &lt;a
href="https://github.com/bytedance/ingress-nginx/pull/2/files"
target="_blank" rel="noreferrer noopener"
>https://github.com/bytedance/ingress-nginx/pull/2/files&lt;/a>&lt;/p>
&lt;p>使用下面这个命令，我们可以测试一下从外部访问服务&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">grpcurl -insecure -servername &lt;span class="s1">&amp;#39;fortune.bytedance.com&amp;#39;&lt;/span> 0.0.0.0:32443 build.stack.fortune.FortuneTeller/Predict
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./19.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;p>刚才也提到了，gRpc 通常是使用 SSL 进行加密的，SSL 的关键在于公钥，私钥以及证书的验证。通过文件系统的方式确实可以处理证书的问题，但 K8s 抽象出 Secret 这种资源，大大提高了对这类文件的管理和复用能力。&lt;/p>
&lt;h4 id="secret" class="relative group">Secret &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#secret" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h4>
&lt;p>Secret 解决了密码、token、密钥等敏感数据的存储问题，主要分为三种类型：&lt;/p>
&lt;ul>
&lt;li>Service Account ：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 / run/secrets/kubernetes.io/serviceaccount 目录中&lt;/li>
&lt;li>Opaque ：Base64 编码格式的 Secret，用来存储密码、密钥等&lt;/li>
&lt;li>kubernetes.io/dockerconfigjson ：用来存储 docker registry 的认证信息&lt;/li>
&lt;/ul>
&lt;p>接下来，我们就来创建一个 Opaque 类型的 Secret，使得 ingress nginx controller 支持服务端的 SSL。
由于篇幅有限，这里简单介绍下证书相关的概念：&lt;/p>
&lt;ul>
&lt;li>CA：证书授权中心(certificate authority)，用来签发私钥，并验证公钥，私钥的合法性&lt;/li>
&lt;li>私钥，公钥：私钥用于加密，公钥用于解密&lt;/li>
&lt;/ul>
&lt;p>Secret 支持不编写 yaml，直接从文件中创建 Secret&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">kubectl create secret generic fortune-teller-ssl-verify &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> --from-file&lt;span class="o">=&lt;/span>ca.crt&lt;span class="o">=&lt;/span>CA.pem &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> --from-file&lt;span class="o">=&lt;/span>tls.crt&lt;span class="o">=&lt;/span>server-public.pem &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> --from-file&lt;span class="o">=&lt;/span>tls.key&lt;span class="o">=&lt;/span>server-private.key
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>修改 Ingress，使其使用新创建的 Secret 提供服务侧的 SSL。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">extensions/v1beta1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Ingress&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">annotations&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">nginx.ingress.kubernetes.io/backend-protocol&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GRPC&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-ingress&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">namespace&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">default&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">rules&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">host&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune.test.com&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">http&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">paths&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">backend&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">serviceName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-service&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">servicePort&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">grpc&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">tls&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">hosts&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">fortune.test.com&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="nt">secretName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">fortune-teller-ssl-verify&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>因为我们使用的是自签名的证书，不被公共的 CA 所信任，所以在发送请求是需要手动指定自己所信任的 CA。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">grpcurl -cacert CA.pem &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -servername &lt;span class="s1">&amp;#39;fortune.test.com&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> 127.0.0.1:32443 &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> build.stack.fortune.FortuneTeller/Predict
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure>
&lt;img class="mx-auto my-0 rounded-md" src="./20.png" alt="" />
&lt;/figure>
&lt;/p>
&lt;h2 id="参考" class="relative group">参考 &lt;span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100">&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#%e5%8f%82%e8%80%83" aria-label="锚点">#&lt;/a>&lt;/span>&lt;/h2>
&lt;ul>
&lt;li>&lt;a
href="https://draveness.me/docker/"
target="_blank" rel="noreferrer noopener"
>https://draveness.me/docker/&lt;/a>&lt;/li>
&lt;li>&lt;a
href="https://www.yuque.com/kshare/2020/fe3b6f86-3b9b-48da-9770-897d838cbf41?language=zh-cn#Namespace"
target="_blank" rel="noreferrer noopener"
>https://www.yuque.com/kshare/2020/fe3b6f86-3b9b-48da-9770-897d838cbf41?language=zh-cn#Namespace&lt;/a>&lt;/li>
&lt;li>&lt;a
href="https://network.51cto.com/art/201907/598970.htm"
target="_blank" rel="noreferrer noopener"
>https://network.51cto.com/art/201907/598970.htm&lt;/a>&lt;/li>
&lt;li>&lt;a
href="https://blog.csdn.net/gatieme/article/details/51383322"
target="_blank" rel="noreferrer noopener"
>https://blog.csdn.net/gatieme/article/details/51383322&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>